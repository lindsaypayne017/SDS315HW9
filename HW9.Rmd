---
title: "HW 9"
author: "Lindsay Payne - UTEID: Lnp832"
output:
  html_document:
    toc: true
    toc_float: true
  pdf_document:
    toc: true
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(fig.height=3, fig.width=4, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=60))
```

----------------------

## Problem 1: Manufacturing Flaws in Curcuit Boards
```{r, echo = FALSE, message = FALSE}
# Load in necessary packages
library(mosaic)
library(tidyverse)
library(ggplot2)
library(knitr)
library(dplyr)
library(broom)
library(kableExtra)
library(effectsize)
```

```{r, echo = FALSE}
# Read in the solder data set
solder <- read.csv("solder.csv")
```

### Part A
```{r, echo = FALSE, message = FALSE, results = 'hide', fig.width = 7, fig.height = 5}
# Create a jitter plot to show relation between opening size and skips
ggplot(solder) + 
  geom_jitter(aes(x = Opening, y = skips), width=0.1) + 
  stat_summary(aes(x = Opening, y = skips), fun='mean', color='red', size=1) +
  labs(
    title = "Number of Solder Skips by Size of Opening on Solder Gun",
    x = "Opening Size",
    y = "Number of Skips",
  ) +
  theme_minimal()

# Calculate the mean skips per size
mean(skips ~ Opening, data=solder) %>%
  round(0)
```

This jitter plot shows that skips were higher overall for circuit boards made using a smaller opening size on the solder gun compared to larger. As seen by the red dots, boards from guns with small openings had 11 average skips, medium openings had 4 average, and large openings had 2 average skips.

```{r, echo = FALSE, message = FALSE, results = 'hide', fig.width = 7, fig.height = 5}
# Create a jitter plot to show relation between thickness alloy and skips
ggplot(solder) + 
  geom_jitter(aes(x = Solder, y = skips), width=0.1) + 
  stat_summary(aes(x = Solder, y = skips), fun='mean', color='red', size=1) +
  labs(
    title = "Number of Solder Skips by Alloy Thickness Used for Soldering",
    x = "Alloy Thickness",
    y = "Number of Skips",
  ) +
  theme_minimal()

# Calculate the mean skips for thick and thin
mean(skips ~ Solder, data=solder) %>%
  round(0)
```

This jitter plot shows that skips were higher overall for circuit boards made using thin alloy compared to thick. As seen by the red dots, boards from thin alloy had 8 average skips while thick had 3 average skips.

### Part B
```{r, echo = FALSE,}
# Create a regression model with skips as the outcome and an Opening:Solder interaction
solder_model = lm(skips ~ Opening + Solder + Opening:Solder, data=solder)

# Get estimates and confidence intervals
estimates <- coef(solder_model)
confints <- confint(solder_model, level = 0.95)

# Add these results into a data frame
coef_table <- data.frame(
  Term = rownames(confints),
  Estimate = round(estimates, 2),
  `Lower Bound` = round(confints[, 1], 2),
  `Upper Bound` = round(confints[, 2], 2),
  row.names = NULL,
  check.names = FALSE
)

# Create a table with estimate and 95% large-sample confidence interval for each coefficient
kable(coef_table, align = "lccc", caption = "Regression Coefficients with 95% Confidence Intervals") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```


### Part C
Although the number of "skips" would logically entail whole-number values, I am reporting coefficient estimates to two decimal places to preserve model precision.

* The baseline for circuit boards made with large openings and thick alloy, therefore not made with medium or small openings or thin alloy, is 0.39 skips.

* The main effect for the medium opening variable (OpeningM) is 2.41 skips. This is the effect of OpeningM in isolation.

* The main effect for the small opening variable (OpeningS) is 5.13 skips. This is the effect of OpeningS in isolation.

* The main effect for the thin alloy variable (SolderThin) is 2.28 skips. This is the effect SolderThin in isolation.

* The interaction effect for the medium opening variable and the thin alloy variable (OpeningM:SolderThin) is -0.74 skips. In other words, circuit boards that are made with a medium sized opening on the solder gun and a thin alloy thickness yield an average number of skips that is 0.74 fewer than what you would expect from summing the individual "isolated" effects of the two variables.

* The interaction effect for the small opening variable and the thin alloy variable (OpeningS:SolderThin) is 9.65 skips. In other words, circuit boards that are made with a small sized opening on the solder gun and a thin alloy thickness yield an average number of skips that is 9.65 more than what you would expect from summing the individual "isolated" effects of the two variables.

### Part D
Based on this analysis, I would recommend the combination of using a solder gun with a large opening and thick alloy for soldering to AT&T because the estimated skips using these baseline levels was 0.39 which was the lowest predicted number of skips among all combinations. For instance, both medium (+2.41 skips with CI: 0.96 to 3.85) and small openings (+5.13 skips with CI: 3.68 to 6.57) result in more skips than large openings. Additionally, thin solder adds +2.28 (CI: 0.84 to 3.72) skips compared to thick solder while the interaction terms do not reduce skips enough to outweigh the increases.

## Problem 2: Grocery Store Prices
```{r, echo = FALSE}
# Read in grocery store data set
groceries <- read.csv("groceries.csv")
```

### Part A
```{r, echo = FALSE, message = FALSE, fig.width = 7, fig.height = 5}
# Find the average price of products for every store
store_price <- groceries %>%
  group_by(Store) %>%
  summarize(avg_price = mean(Price)) %>%
  arrange(avg_price)

# Plot the average prices for different stores
ggplot(store_price) +
  geom_col(aes(x = reorder(Store, avg_price), y = avg_price), fill = "skyblue2") +
  coord_flip() +
  labs(
    title = "Average Price of Products by Store",
    x = "Store",
    y = "Average Price ($) of Products Sold at That Store"
  ) +
  theme_minimal()
```

This bar chart shows the average price ($) of grocery products at each store. As seen in the plot, the stores Whole Foods and Wheatsville Food Co-Op have higher average prices of products, while traditional full-sized grocery chains like Walmart and Fiesta tend to be lower.

### Part B
```{r, echo = FALSE, message = FALSE, fig.width = 7, fig.height = 6}
# Create a new Store2 variable that combines Store and City
groceries <- groceries %>%
  mutate(Store2 = paste(Store, City, sep = " - "))

# Count how many distinct stores carry each product
product_counts <- groceries %>%
  distinct(Product, Store2) %>%
  group_by(Product) %>%
  summarize(store_count = n()) %>%
  arrange(store_count)

# Plot the product and number of stores selling that product
ggplot(product_counts) +
  geom_col(aes(x = reorder(Product, store_count), y = store_count), fill = "skyblue2") +
  coord_flip() +
  labs(
    title = "Products by the Number of Stores Selling That Product",
    x = "Product",
    y = "Number of Stores Selling That Product",
  ) +
  theme_minimal()
```

This bar graph displays products by the number of stores selling that product. As seen by the graph, staples like Horizon 2% Milk and a carton of eggs are sold in all 16 stores while other products, such as Cinnamon Toast Crunch, are only sold in a few specialty locations.

### Part C
```{r, echo = FALSE, results = 'hide'}
# Create a linear regression model for price by product and type
type_lm <- lm(Price ~ Product + Type, data = groceries)

# Find the coefficients and 95% confidence intervals of the coefficients
coef(type_lm)
confint(type_lm)

# Find the specific confidence interval for Grocery
confint(type_lm)["TypeGrocery", ] %>% round(2)
```

Compared with ordinary grocery stores (like Albertsons, HEB, or Krogers), convenience stores charge somewhere between 0.41 and 0.92 dollars more for the same product.

### Part D
```{r, echo = FALSE, results = 'hide'}
# Create a linear regression model for price by product and store
store_lm <- lm(Price ~ Product + Store2, data = groceries)

# Find the coefficients and 95% confidence intervals of them
coef(store_lm)
confint(store_lm)
```

When comparing the same product, the stores Walmart Houston (-1.01) and Kroger Fresh Fare Houston (-0.92) seem to charge the lowest prices. Meanwhile, the stores Whole Foods Austin (+0.46) and Wheatsville Food Co-Op Austin (+0.29) seem to charge the highest prices when comparing the same product.

### Part E
As seen by our fitted model in part D, Central Market had a coefficient of -0.57 while HEB Austin had one of -0.62 and HEB Houston had one of -0.75. This means that Central Market charges about 5 cents more than HEB Austin (-0.57 - (-0.62) = 0.05) and 18 cents more than HEB Houston (-0.57 - (-0.75) = 0.18) for the same product. While this supports the idea that Central Market is slightly more expensive, the HEB/Central Market difference for the same products are small, especially when compared to larger pricing gaps across other stores. For example, Whole Foods Austin had a coefficient of 0.46 meaning Central Market charged about $1.03 less than Whole Foods (-0.57 - 0.46 = -1.03), and Walmart Houston had a coefficient of -1.01 which means Central Market charged 44 cents more than Walmart (-0.57 - (-1.01) = 0.44). Therefore, Central Market charges a similar amount to HEB for the same product, and the store's premium price reputation likely comes more from selling different products that are inherently more expensive and not from price discrimination on shared items.

### Part F
```{r, echo = FALSE, results = 'hide'}
# Make a new variable Income10K that scales income values so that 1 unit = $10,000
groceries <- groceries %>%
  mutate(Income10K = Income / 10000)

# Create a linear regression model for price by product and Income10k
income_lm <- lm(Price ~ Product + Income10K, data = groceries)
coef(income_lm)
confint(income_lm)

# Standardize the coefficients
standardize_parameters(income_lm)
```


Based on the negative sign of the Income10K coefficient, consumers in poorer ZIP codes seem to pay more for the same product, on average. This is because the regression model controls for product, so the coefficient for Income10K represents the effect of ZIP code income holding the product constant. Our negative coefficient (-0.014 with a 95% CI: -0.033 to 0.005) means that as income increases, the expected price of a product decreases slightly. This suggests that people in lower-income areas pay more for the same items. However, the confidence interval includes 0, so this effect is not statistically significant at the 0.05 level, meaning we are not fully confident that the observed relationship isn’t due to chance.

The standardized coefficient on Income10K is -0.03. A one-standard deviation increase in the income of a ZIP code seems to be associated with a 0.03 standard-deviation decrease change in the price that consumers in that ZIP code expect to pay for the same product.

## Problem 3: Redlining
```{r, echo = FALSE}
# Load in the redlining data set
redlining <- read.csv("redlining.csv")
```

### Part A
True

* Figure A1 shows a scatter plot with a clear positive relationship between percentage of minority residents and FAIR policies per 100 housing units. As seen by both the data points on the plot and the upward sloping trend line, when minority percentage increases within a ZIP code the number of FAIR policies tends to increase. Additionally, according to the model_A regression results, the coefficient for minority is 0.014, meaning each 1% point increase in minority residents is associated with an increase of 0.014 FAIR policies per 100 housing units. Because the p-value for this estimate is 0.000 and the 95% confidence interval of [0.009, 0.018] does not contain 0, this estimate is statistically significant. Furthermore, the R² is 0.516, suggesting that about 51.6% of the variation in FAIR policies is explained by minority percentage.

### Part B
Undecidable

* While both minority and age are included as main effects on policies in model_E, which is at least partially relevant, no interaction term between them has been tested in any of the regression models. Therefore, we don’t have enough information to say whether such an interaction exists or not. To determine its presence, we would need to fit a model that explicitly includes a "minority:age" interaction term and then assess its statistical significance.

### Part C
False

* The estimate of -0.001 for the interaction term "minority:fire_riskLow" in the regression table for model_C, which includes an interaction term between minority percentage and fire risk, suggests that the minority effect on FAIR policies is 0.001 lower in low fire-risk ZIP codes than in high-risk ones. However, this effect is basically zero with a p-value of 0.839, making the estimate not significant. Similarly, the slopes of the trend lines in Figure C1 do not appear to be drastically different. Since no statistically significant difference exists between high and low-risk areas in the effect of minority percentage, the claim that it's stronger in high-fire-risk ZIP codes is unsupported.

* As a correction, the statement can change to say that the relationship between minority percentage and the number of FAIR policies per 100 housing units is statistically similar in high and low-fire-risk ZIP codes.

### Part D
False

* According to model_D1, the minority coefficient was 0.014 with p-value of 0 which suggests a significant positive correlation. Meanwhile, model_D2 shows a still statistically significant minority coefficient of 0.010 with p-value 0.002 and an income coefficient of -0.074 with p-value 0.041. This entails that income is a meaningful control as it reduces the size of the minority coefficient from 0.014 to 0.010. However, it does not eliminate the association since the effect of minority percentage on FAIR policies remains statistically significant.

* Rather than income "explaining away" the relationship, the statement could be corrected by saying that income only partially accounts for the relationship between minority percentage and FAIR policy uptake.

### Part E
True

* In model_E, which controls for income, fire risk, and housing age, the coefficient estimate for minority was 0.008 with a p-value of 0.006 and confidence interval (0.003, 0.014) which does not include 0. Therefore, the estimate is statistically significant.
Even after controlling for income, fire risk, and housing age, the percentage of minority residents is still significantly associated with increased FAIR policy uptake. This suggests the association is not fully explained by these other variables.